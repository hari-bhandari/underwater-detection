
\chapter{Introduction}
\section{Background and Motivation}
It is a well known fact that almost 71 percent of the Earths surface is covered by water  \cite{usgs_water_coverage}, yet much of this vast domain remains only barely explored or monitored  \cite{krishnan2021underwater}. Over the last few decades, computing power and data gathering improvements have changed how we perceive images, whether taken underwater or on land. In particular, deep learning has secured a significant role in computer vision, especially for object detection and classification tasks. Initially, CNN led this movement \cite{easyodm2024cnn}, as they were able to learn hierarchical patterns directly from raw image pixels. Landmark achievements in famous competitions like ImageNet showed that CNNs could surpass earlier, manually engineered feature extraction methods. \cite{viso2025object, mdpi2025survey,paperswithcode2020detr} Soon afterwards, these architectures found practical uses in diverse areas, including self-driving cars and diagnostic imaging in healthcare.
    
Modern society relies increasingly on accurate and timely object detection.\cite{viso2025object} Vehicles in crowded environments depend on real-time detection for collision avoidance, and robots in industrial settings identify items for sorting or assembly. Elsewhere, drone systems scan large fields to locate pests or crop damage, while medical scanning tools focus on identifying tumours. Despite these distinct contexts, all share a common need: robust detection under changing conditions, such as scale differences or partial occlusions. Over time, researchers have pushed detection models to achieve higher accuracy and quicker inference times.

However, fulfilment of these diverse needs remains quite a challenge. The Models that run rapidly may sacrifice accuracy, whereas more accurate models with complex architectures tend to demand extensive computational resources and may also need a larger amount of training data, which is already very limited in this field. Similarly, with datasets growing in both size and complexity, capturing both fine local details and broader global context becomes a delicate balancing act. CNN-based methods continue to lead the field, yet their reliance on convolutional receptive fields motivates others to explore different architectures. This has led to the rise of transformer-based object detectors, whose origins lie in natural language processing but have now been adapted for visual data. Although these approaches can model extensive context, they typically need far more data and computational power \cite{edgeaivision2024vision}. Therefore, some top researchers propose hybrid architectures, combining CNN layers with Transformer-style attention to capture the strengths from both to achieve higher accuracy.

Despite this fantastic research community, the field remains somewhat fragmented. Numerous new studies focus on refining one form of architecture, or they compare multiple methods under different conditions, making it difficult to identify a clear overall leader. Researchers face inconsistent needs, such as balancing speed and accuracy or dealing with limited hardware.

In the coming chapters, this report will compare three main categories of models: CNN-based, Transformer-based, and hybrid solutions in controlled experiments. This study aims to help researchers and real-world users select a detection method aligned with their specific requirements.

\section{Problem Statement}
Although the study of deep learning has made significant progress in object detection, it has also increased the complexity of available approaches. Experts can now choose from CNN-based models, Transformer-based frameworks, or hybrid blends of the two. Each framework offers different advantages, ranging from enhanced global context representation, as seen in Transformers, to superior real-time performance and state-of-the-art benchmark results, as demonstrated by CNN-based models. However, there remains no conclusive agreement on which approach objectively exceeds the others when evaluated under equivalent conditions.
The primary problem is the lack of uniform, head-to-head comparisons of CNN-based, Transformer-based, and hybrid solutions using identical datasets, metrics, and computational setups.\cite{mdpi2025survey} Past research papers often showcase enhancements in a single type of model or address specialised tasks, leaving open questions about general applicability. This gap greatly hampers progress in both academic and industrial contexts. Therefore, a comprehensive examination is very much required to clarify which architectures are more suitable when concerns like speed, precision, or resource constraints play a dominant role.


\section{Significance and potential Applications}

Object detection is indispensable in many fields, prompting safety, efficiency, and precision innovations. Self-driving vehicles rely on continuous identification of other cars, pedestrians, and road signs \cite{mdpi2023comparative}, while drone-based agriculture systems evaluate plant health across extensive farmlands. \cite{mdpi2024enhancing} In the industry, automated inspection can rapidly spot defective products, streamline quality control processes, and cut costs.\cite{mdpi2025survey} Clarifying how different detection approaches measure up under standardised tests helps engineers and developers choose the best solutions based on their domainâ€™s specific needs, be it minimal inference time or top accuracy in cluttered scenes.\cite{medium2024vision}
From a theoretical perspective, the main purpose of this study is to serve as a structured reference. This paper addresses existing literature gaps by systematically evaluating each major model family under consistent testing conditions. A thorough comparative study identifies promising areas for future improvements and stresses possible performance bottlenecks in each approach. Ultimately, it also provides a deeper understanding of CNN-based, Transformer-based, and hybrid methodologies that can advance object detection research, particularly underwater object detection. \cite{mdpi2024enhancing}
